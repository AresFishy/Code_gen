{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import tensorflow as tf\n",
    "import edward as ed\n",
    "from edward.models import Normal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style('oceans16')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/fake_or_real_news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrds = word_tokenize(bb)\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = [word for word in wrds if word.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LCVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(LCVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (lemmatizer.lemmatize(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = LCVectorizer(max_df=0.95, min_df=2, stop_words='english', decode_error='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = tf_vectorizer.fit_transform(wrds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=11, max_iter=10,\n",
    "                               learning_method='online',\n",
    "                               learning_offset =50.,\n",
    "                               random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=11, n_jobs=1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_features = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for index, topic in enumerate(model.components_):\n",
    "        message = \"\\nTopic #{}:\".format(index)\n",
    "        message += \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1 :-1]])\n",
    "        print(message)\n",
    "        print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #0:clinton afraid awkwardly smoke belief warned know cnn accusing people comey scandal cover lie credibility want obama really political just public associate hatch medium time campaign victory question stretch kgb gone fear assault hoover new act trump explanation reason like\n",
      "======================================================================\n",
      "\n",
      "Topic #1:fear setup lie like new fighting decided try nominee strategy foundation accusing reason credibility really tell director assault afraid kgb year awkwardly know doj campaign old violating countless medium republican hatch knew james war associate explanation conspiracy hoover presidential hillary\n",
      "======================================================================\n",
      "\n",
      "Topic #2:fbi people old right wing presidential hatch political james leadership act cnn bigger tell know going setup near obama bizarre panicked explanation public unprecedented clintonworld house medium fear victory scandal associate republican year just final democrat agent really new hubris\n",
      "======================================================================\n",
      "\n",
      "Topic #3:campaign time going want reason presidential final republican doj conspiracy act attack decided bizarre kgb house bigger comey ally investigation unprecedented credibility fighting assault agent nominee try awkwardly really near year question strategy right violating director explanation victory belief gone\n",
      "======================================================================\n",
      "\n",
      "Topic #4:unprecedented gone associate democrat hatch director near focused explanation ally violating agent really foundation letter setup house reason lie nominee political want war bigger question countless public awkwardly act belief try warned right smoke time stretch hillary email wing year\n",
      "======================================================================\n",
      "\n",
      "Topic #5:email investigation cover tell wrong behavior bizarre trump york associate hoover nominee war try agent accusing strategy gone decided election right assault lie desperation ally explanation just near director political wing time scandal countless credibility doj hubris presidential hatch act\n",
      "======================================================================\n",
      "\n",
      "Topic #6:bigger desperation obama year knew countless foundation afraid campaign wrong panicked lie scandal attack ally kgb violating credibility york belief trump letter fighting accusing decided like really director know public cnn smoke question fbi bizarre hatch people fear democrat just\n",
      "======================================================================\n",
      "\n",
      "Topic #7:election james question public leadership letter hoover strategy unprecedented gone agent credibility wrong kgb warned stretch explanation attack presidential obama fear foundation right comey fbi way like violating panicked try desperation victory people afraid fighting setup doj really investigation final\n",
      "======================================================================\n",
      "\n",
      "Topic #8:comey just war act medium assault time wrong associate cover obama scandal smoke hatch stretch bizarre right panicked victory letter really presidential kgb email behavior bigger like campaign afraid conspiracy lie know awkwardly setup political agent hillary desperation nominee public\n",
      "======================================================================\n",
      "\n",
      "Topic #9:hillary panicked victory clintonworld credibility election people republican presidential near act war ally explanation scandal wing question new behavior doj decided clinton gone assault conspiracy time trump final campaign awkwardly james cnn going leadership comey email stretch agent unprecedented nominee\n",
      "======================================================================\n",
      "\n",
      "Topic #10:scandal way really kgb political attack hubris house stretch hillary election fear campaign gone act bigger desperation agent belief explanation just try republican foundation afraid new lie panicked comey director assault york fighting clinton hatch know leadership presidential final letter\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print_top_words(lda, tf_features, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic = lda.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import sentiment_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 89)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
